{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "This notebook illustrates how to use feature generation and feature selection to improve predictions from a machine learning model. The dataset used in this notebook is from the [Avazu Click-Through Rate Prediction contest](https://www.kaggle.com/c/avazu-ctr-prediction/overview) and is a binary classification dataset. The topics covered here are count encoding of categorical features, creation of interaction features, and three different approaches to feature selection. After each feature selection method, a decision tree is trained and its performance is compared to the performance of a decision tree trained using all available features. Data leakage isn't discussed here but the feature selection methods use the training data only.\n",
    "\n",
    "# Imports and Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575 23\n",
      "0    881077\n",
      "1    167498\n",
      "Name: click, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>app_category</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000010e+18</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000020e+19</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000040e+19</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000060e+19</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000070e+19</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18993</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      hour    C1  banner_pos   site_id site_domain  \\\n",
       "0  1.000010e+18  14102100  1005           0  1fbe01fe    f3845767   \n",
       "1  1.000020e+19  14102100  1005           0  1fbe01fe    f3845767   \n",
       "2  1.000040e+19  14102100  1005           0  1fbe01fe    f3845767   \n",
       "3  1.000060e+19  14102100  1005           0  1fbe01fe    f3845767   \n",
       "4  1.000070e+19  14102100  1005           1  fe8cc448    9166c161   \n",
       "\n",
       "  site_category    app_id app_domain app_category  ... device_type  \\\n",
       "0      28905ebd  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "1      28905ebd  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "2      28905ebd  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "3      28905ebd  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "4      0569f928  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "\n",
       "  device_conn_type    C14  C15  C16   C17  C18  C19     C20  C21  \n",
       "0                2  15706  320   50  1722    0   35      -1   79  \n",
       "1                0  15704  320   50  1722    0   35  100084   79  \n",
       "2                0  15704  320   50  1722    0   35  100084   79  \n",
       "3                0  15706  320   50  1722    0   35  100084   79  \n",
       "4                0  18993  320   50  2161    0   35      -1  157  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file= pd.read_csv('C:\\\\Users\\\\16479\\\\Documents\\\\ad_clicks\\\\train_small_version.csv', delimiter= ',')\n",
    "data= file.drop(['click'], axis= 1) #labels column\n",
    "labels= file['click']\n",
    "N,d= np.shape(data)\n",
    "print(N,d)\n",
    "print(labels.value_counts())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has **1,048,575 examples**, each characterized by **23 features**. The label for each example is one of **0** or **1** with there being many more instances of examples with the label 0.\n",
    "\n",
    "It may be obvious by looking at the head of the dataset, but let's see what data types we're working with for each of the features. Also, since scikit learn machine learning models can't handle NaNs, let's ensure that there are no NaNs as any of the feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  float64\n",
      "hour                  int64\n",
      "C1                    int64\n",
      "banner_pos            int64\n",
      "site_id              object\n",
      "site_domain          object\n",
      "site_category        object\n",
      "app_id               object\n",
      "app_domain           object\n",
      "app_category         object\n",
      "device_id            object\n",
      "device_ip            object\n",
      "device_model         object\n",
      "device_type           int64\n",
      "device_conn_type      int64\n",
      "C14                   int64\n",
      "C15                   int64\n",
      "C16                   int64\n",
      "C17                   int64\n",
      "C18                   int64\n",
      "C19                   int64\n",
      "C20                   int64\n",
      "C21                   int64\n",
      "dtype: object\n",
      "There are no NaNs in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n",
    "if data.isnull().values.any() == False:\n",
    "    print('There are no NaNs in the dataset')\n",
    "else:\n",
    "    print('There are NaNs in the dataset. Must address before proceeding since most machine learning models cannot handle NaN values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those features that are of type \"object\" are categorical while those that are of either type \"float64\" and \"int64\" are numerical. Since not all machine learning models can handle categorical features, we will encode these categorical features later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Elimination\n",
    "Now that we have a nice overview of the dataset we're working with, let's see if there are any features that we want to exclude and if there are any features that we should make interaction features with. For every feature, we'll count how many unique entries there are. If the number of unique entries is greater than 25% of the number of examples, that particular feature will be excluded. Having ~250,000 (25% x 1,048,575) unique entries for one feature means that, for each possible value of this feature, only ~4 examples have the same value, meaning the feature likely isn't very informative for what we're trying to predict. Just like how having all examples having the same feature value for a particular feature isn't very useful for making predictions, having all examples having different values for the same feature likely isn't useful either.\n",
    "\n",
    "Also for every feature, if the number of unique values is less than 25, we'll create interaction features (later but we'll get the names of those particular columns now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to eliminate: ['id' 'device_ip']\n",
      "Features to create interaction features with: ['hour' 'C1' 'banner_pos' 'site_category' 'app_category' 'device_type'\n",
      " 'device_conn_type' 'C15' 'C16' 'C18']\n"
     ]
    }
   ],
   "source": [
    "pop_cols= np.array([]) #store names of columns that won't be used in ML model\n",
    "pop_thresh= N/4\n",
    "interact_feats= np.array([]) #store names of cols to make interaction features with later\n",
    "for i in data.columns:\n",
    "    unique_col_entries= data[i].nunique()\n",
    "    if unique_col_entries > pop_thresh:\n",
    "        pop_cols= np.append(pop_cols, i)\n",
    "    elif unique_col_entries < 25:\n",
    "        interact_feats= np.append(interact_feats, i)\n",
    "        \n",
    "print('Features to eliminate:', pop_cols)\n",
    "print('Features to create interaction features with:', interact_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "## Count Encode Categorical Features\n",
    "For all categorical features, all feature values will be **count-encoded**. This means that, for each categorical feature, an integer of the total number of times a particular level appears in the dataset will replace every instance of that level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountEncoder(cols=Index(['site_id', 'site_domain', 'site_category', 'app_id', 'app_domain',\n",
       "       'app_category', 'device_id', 'device_ip', 'device_model'],\n",
       "      dtype='object'),\n",
       "             combine_min_nan_groups=True, drop_invariant=False,\n",
       "             handle_missing='count', handle_unknown=None, min_group_name=None,\n",
       "             min_group_size=None, normalize=False, return_df=True, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_feats= data.select_dtypes(include= [\"category\", object]).columns\n",
    "count_enc= ce.CountEncoder(cols= categ_feats)\n",
    "count_enc.fit(data[categ_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've expressed the categorical features in a quantitative way, we won't use the original categorical variables in our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_cols= np.append(pop_cols, categ_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interaction Features\n",
    "For all original features that have <25 unique entries, we'll create interaction features among them. First we'll convert any numerical features that meet this criterion to string, then we'll create new columns of strings that represent interactions, and then we'll count encode these so our final interaction feature values are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to hold interaction features. \n",
    "#need index to match that of the original feature values in order to combine later\n",
    "interact_df= pd.DataFrame(index= data.index)\n",
    "for feat1, feat2 in itertools.combinations(interact_feats, 2):\n",
    "    interact_col= \"_\".join([feat1, feat2])\n",
    "    interact_vals= data[feat1].map(str) + \"_\" + data[feat2].map(str)\n",
    "    interact_df[interact_col]= ce.CountEncoder().fit_transform(interact_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've generated these count encoded features, let's add them to the end of our original dataframe that contains all of the original feature values. We'll also drop all of the features/columns we don't want to include to make our predictions in our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048575, 67)\n"
     ]
    }
   ],
   "source": [
    "#count encoded categorical features\n",
    "data= data.join(count_enc.transform(data[categ_feats]).add_suffix(\"count\"))\n",
    "#count encoded interaction features\n",
    "data= data.join(interact_df)\n",
    "#drop columns\n",
    "data.drop(pop_cols, axis= 1, inplace= True)\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "The feature generation process resulted in us doubling the number of features! There's a possibility that not all of these features will be helpful to us trying to complete this binary classification task. We will try three different approaches to feature selection and see what our prediction performance is like with each one. For each approach, the machine learning model will be a decision tree with the same hyperparameter settings. Since the dataset is imbalanced, the performance metrics will be precision and recall.\n",
    "\n",
    "First let's split the dataset into a training and validation set (80/20 split) (the Avazu dataset has a separate test set file that hasn't been included in this notebook but should be used as the test set once you're happy with your feature selection approach and trained machine learning model). We'll also train our decision tree using all features to have a baseline to compare the three approaches to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data precision: 0.6015003674179356 Training data recall: 0.923388817265806\n",
      "Development data precision: 0.3026017076845806 Development data recall: 0.6232340839957854\n"
     ]
    }
   ],
   "source": [
    "x_train, x_devel, y_train, y_devel= train_test_split(data, labels, test_size= 0.2, random_state= 0)\n",
    "N,d= np.shape(x_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score\n",
    "\n",
    "def train_eval_tree(x_train, y_train, x_devel, y_devel):\n",
    "    \"\"\"Function that trains and evaluates the performance of a decision tree\n",
    "    Inputs: training data feature values, training data labels, development data feature values, development data labels\n",
    "    Outputs: None (model performance on training and development sets printed to screen)\n",
    "    \"\"\"\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_predicts= tree.predict(x_train)\n",
    "    train_recall= balanced_accuracy_score(y_train, train_predicts)\n",
    "    train_precision= precision_score(y_train, train_predicts)\n",
    "    \n",
    "    devel_predicts= tree.predict(x_devel)\n",
    "    devel_recall= balanced_accuracy_score(y_devel, devel_predicts)\n",
    "    devel_precision= precision_score(y_devel, devel_predicts)\n",
    "    \n",
    "    print('Training data precision:', train_precision, 'Training data recall:', train_recall)\n",
    "    print('Development data precision:', devel_precision, 'Development data recall:', devel_recall)\n",
    "    return\n",
    "\n",
    "tree= DecisionTreeClassifier(random_state= 0, class_weight= \"balanced\")\n",
    "train_eval_tree(x_train, y_train, x_devel, y_devel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: L1 Regularization\n",
    "This feature selection method involves training a linear model that uses an L1 penalty. All features are used to train this model and the L1 penalty causes the weight/contribution of unimportant features to be zero. We then extract the non-zeroed features and use them in our decision tree. An important note on this feature selection method is that it considers all features and how they collectively contribute to each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16479\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features retained: Index(['C1', 'banner_pos', 'device_type', 'device_conn_type', 'C14', 'C16',\n",
      "       'C17', 'C18', 'C19', 'C21'],\n",
      "      dtype='object')\n",
      "Number of features retained: (10,)\n",
      "Training data precision: 0.2634580311025102 Training data recall: 0.6666607907057926\n",
      "Development data precision: 0.2658021612635079 Development data recall: 0.6650065298286877\n"
     ]
    }
   ],
   "source": [
    "#train linear model with L1 penalty\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc= LinearSVC(C= 1.0, penalty= 'l1', dual= False).fit(x_train, y_train)\n",
    "svc_mod= SelectFromModel(lsvc, prefit= True)\n",
    "\n",
    "#get training set that contains only the non-zeroed features\n",
    "x_train_new= svc_mod.transform(x_train)\n",
    "\n",
    "#get development set that contains only the non-zeroed features\n",
    "selected_feats= pd.DataFrame(svc_mod.inverse_transform(x_train_new), index= x_train.index, columns= x_train.columns)\n",
    "selected_cols= selected_feats.columns[selected_feats.var() != 0]\n",
    "x_devel_new= x_devel[selected_cols]\n",
    "\n",
    "#out of curiousity, see which features were retained\n",
    "print('Features retained:',selected_cols)\n",
    "print('Number of features retained:',np.shape(selected_cols)[0])\n",
    "\n",
    "#train and test decision tree using only these features\n",
    "tree.fit(x_train_new, y_train)\n",
    "train_eval_tree(x_train_new, y_train, x_devel_new, y_devel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to our baseline, our performance improved a bit! We can see that we're not overfitting to the training data and that our recall improved. Pretty cool considering we didn't make any changes to the model itself, just the features we were providing to it. Let's see if we see the same thing with the other two methods!\n",
    "\n",
    "## Method 2: SelectKBest using the f_classif score\n",
    "This feature selection method involves evaluating the linear relationship between each feature and the label/target. The top-k features with the strongest relationship with the label are identified and are used in our decision tree. We will use the top 10 best features since this was the number of features retained when the L1 regularization method was used. Unlike the L1 regularization method, this is a univariate method, meaning that each feature is considered individually/one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features retained: Index(['C14', 'C16', 'C17', 'app_idcount', 'app_domaincount',\n",
      "       'app_categorycount', 'C1_app_category', 'banner_pos_C15',\n",
      "       'app_category_device_conn_type', 'C15_C16'],\n",
      "      dtype='object')\n",
      "Training data precision: 0.26708503114210363 Training data recall: 0.6837288688338524\n",
      "Development data precision: 0.26600646304597103 Development data recall: 0.6757845995459122\n"
     ]
    }
   ],
   "source": [
    "#get the 10 best features\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "select_feats= SelectKBest(f_classif, k= 10)\n",
    "\n",
    "#get training set that has only the top 10 features\n",
    "x_train_new= select_feats.fit_transform(x_train, y_train)\n",
    "\n",
    "#get development set that has only the top 10 features\n",
    "selected_feats= pd.DataFrame(select_feats.inverse_transform(x_train_new), index= x_train.index, columns= x_train.columns)\n",
    "selected_cols= selected_feats.columns[selected_feats.var() != 0]\n",
    "x_devel_new= x_devel[selected_cols]\n",
    "\n",
    "#out of curiousity, see which features were retained\n",
    "print('Features retained:',selected_cols)\n",
    "\n",
    "#train and test decision tree using only these features\n",
    "tree.fit(x_train_new, y_train)\n",
    "train_eval_tree(x_train_new, y_train, x_devel_new, y_devel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also see a bit on an improvement in model performance compared to our baseline. We also see that the feature set from the two feature selection methods is different. For the L1 regularization method, only features from the original 23 features were identified as being the best for this particular prediction task. For the SelectKBest-f_classif method, features from the original feature set as well as some of the features from our feature generation methods were among the top 10 most important features. For example, \"C1_app_category\" is the interaction between the features \"C1\" and \"app_category\" and \"app_idcount\" is the count encoded version of the original feature \"app_id\".\n",
    "\n",
    "## Method 3: Decision Trees/Random Forests for Feature Selection\n",
    "The final feature selection method considered in this notebook is the decision tree. This method is favourable because decision trees naturally rank features by how well they distinguish classes. Features that best split/distinguish classes are evaluated at nodes at the base/start of a tree. Therefore, if we prune a tree at a certain node, we can get a subset of the most informative features.\n",
    "\n",
    "Implementing this feature selection method involves training a decision tree or random forest (an ensemble of decision trees) and identifying the features that have an importance greater than some threshold. These features are the ones used in your machine learning model (in this case, also a decision tree!). For this example, an arbitrary threshold of 0.10 will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_ipcount\n",
      "device_modelcount\n",
      "Training data precision: 0.2519334697518233 Training data recall: 0.65733244916212\n",
      "Development data precision: 0.22954234613361388 Development data recall: 0.6132362944478313\n"
     ]
    }
   ],
   "source": [
    "#train a random forest using all features and get the most important features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest= RandomForestClassifier(n_estimators= 1000, random_state= 0)\n",
    "forest.fit(x_train, y_train)\n",
    "selector= SelectFromModel(forest, threshold= 0.10)\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "#out of curiousity, see which features were retained and their importance\n",
    "for important_feats in selector.get_support(indices= True):\n",
    "    print(x_train.columns[important_feats])\n",
    "x_train_new= selector.transform(x_train)\n",
    "x_devel_new= selector.transform(x_devel)\n",
    "    \n",
    "#train and test decision tree using only these features\n",
    "tree.fit(x_train_new, y_train)\n",
    "train_eval_tree(x_train_new, y_train, x_devel_new, y_devel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "This notebook presented some feature generation and feature selection techniques. This notebook is not exhaustive but it demonstrates that identifying important features via feature selection can improve the performance of a machine learning model without having to make any changes to the model itself. There's no one-size-fits-all approach to feature generation and feature selection, but hopefully this provides a start to improving your models' performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
